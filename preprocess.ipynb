{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RktuaFKYlVu"
      },
      "source": [
        "## 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcOkmiWFX_WC",
        "outputId": "4b7e36e2-b0db-4fa4-9529-eff1d208dcc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Question                                             Answer\n",
            "0            안녕하세요?  안녕하세요!저는 'Coala'입니다. 여러분의 파이썬 학습 도우미에요. Meta의 ...\n",
            "1          당신은 뭐예요?  안녕하세요!저는 'Coala'입니다. 여러분의 파이썬 학습 도우미에요. Meta의 ...\n",
            "2         코알라가 뭔가요?  안녕하세요!저는 'Coala'입니다. 여러분의 파이썬 학습 도우미에요. Meta의 ...\n",
            "3  코알라는 어떻게 만들어졌나요?  안녕하세요!저는 'Coala'입니다. 여러분의 파이썬 학습 도우미에요. Meta의 ...\n",
            "4             누구세요?  안녕하세요!저는 'Coala'입니다. 여러분의 파이썬 학습 도우미에요. Meta의 ...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/data_Inspection - 시트12 (1).csv'\n",
        "\n",
        "\n",
        "# CSV 파일 읽기\n",
        "df = pd.read_csv(file_path, encoding='utf-8')\n",
        "\n",
        "# 데이터 확인\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCaEpYXrx-PO",
        "outputId": "26b6a6ab-08b9-4de3-9374-5dddd2d2733a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "960"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import pandas as pd\n",
        "import json\n",
        "\n",
        "# 먼저 모든 행을 'qas' 형식으로 변환\n",
        "qas_list = df.apply(lambda row: {'qas': [{'question': row['Question'], 'answers': [{'text': row['Answer']}]}]}, axis=1).tolist()\n",
        "\n",
        "# 변환된 데이터를 JSON 파일로 저장\n",
        "json_file_path = '/content/final-data.json'\n",
        "with open(json_file_path, 'w', encoding='utf-8') as file:\n",
        "    json.dump(qas_list, file, ensure_ascii=False)\n",
        "\n",
        "\n",
        "# 저장된 JSON 파일 경로 반환\n",
        "json_file_path\n",
        "#길이\n",
        "len(qas_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCk2ST2myKHh",
        "outputId": "ed80caf3-e9c4-4edf-b656-cc602d99d7b1"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# JSON 파일을 읽습니다.\n",
        "with open('/content/final-data.json', 'r') as f:\n",
        "    dev_data = json.load(f)\n",
        "\n",
        "# dev_data를 정제하여 refined_dict 생성\n",
        "refined_dict = {}\n",
        "for original_dict in dev_data:\n",
        "    for entry in original_dict['qas']:\n",
        "        question = entry['question']\n",
        "        answers = [ans['text'] for ans in entry['answers']][0]\n",
        "        refined_dict[question] = answers\n",
        "\n",
        "#print(refined_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN1rAQd-yg3M",
        "outputId": "3eaab8a0-c60a-45e4-cadd-2e0b0e1ef706"
      },
      "outputs": [],
      "source": [
        "final_prompt_list = []\n",
        "\n",
        "for idx, (question, answer) in enumerate(refined_dict.items()):\n",
        "    prompt = f\"Below is an instruction that describes a task. Write a response that appropriately completes the request. ### Instruction: {question} ### Response: {answer}\"\n",
        "    #print(idx, prompt)\n",
        "    prompt_dict = {}\n",
        "    prompt_dict['text'] = prompt\n",
        "    final_prompt_list.append(prompt_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vybvvQtKY5l8",
        "outputId": "a71f34ed-9be2-497c-9566-c40456cf3910"
      },
      "outputs": [],
      "source": [
        "final_prompt_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1r-SARzZJhp"
      },
      "source": [
        "## Json 파일 형태로 저장 및 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk6PEiNRY7qm"
      },
      "outputs": [],
      "source": [
        "with open('/content/final-data.json', 'w', encoding='utf-8') as f:\n",
        "    f.write(\"[\\n\")\n",
        "    for i, item in enumerate(final_prompt_list):\n",
        "        json_str = json.dumps(item, ensure_ascii=False)\n",
        "        f.write(json_str)\n",
        "        if i < len(final_prompt_list) - 1:  # 마지막 원소가 아니라면 콤마를 추가\n",
        "            f.write(\",\\n\")\n",
        "        else:  # 마지막 원소라면 콤마를 추가하지 않음\n",
        "            f.write(\"\\n\")\n",
        "    f.write(\"]\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9iCpwv2Zxnf"
      },
      "source": [
        "# fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5c-AlidZorl",
        "outputId": "91bbeed0-5fea-44d5-9625-381862dd6823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Jan 28 10:19:37 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mG6JJOoZ9_k"
      },
      "source": [
        "## autotrain-advanced 모듈 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPePQzL4Z0zK",
        "outputId": "0829c4f3-e913-457c-915b-56b016d8ddf2"
      },
      "outputs": [],
      "source": [
        "!pip install -q autotrain-advanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPeAKIc1aMLB"
      },
      "source": [
        "## Torch update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vM8JMPuxaCNf",
        "outputId": "037be292-ee7e-4b2c-d316-5666eb3ec4ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[1mINFO    Installing latest xformers\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest xformers\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest PyTorch\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest PyTorch\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!autotrain setup --update-torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnhBLCN2adgV"
      },
      "source": [
        "## 허깅페이스 토큰 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEvNQiQ_aS8r",
        "outputId": "24016774-cbcb-4a34-df10-8d5665f9d8c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/huggingface-cli\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/commands/huggingface_cli.py\", line 49, in main\n",
            "    service.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/commands/user.py\", line 98, in run\n",
            "    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/_login.py\", line 113, in login\n",
            "    interpreter_login(new_session=new_session, write_permission=write_permission)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/_login.py\", line 192, in interpreter_login\n",
            "    _login(token=token, add_to_git_credential=add_to_git_credential, write_permission=write_permission)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/_login.py\", line 305, in _login\n",
            "    raise ValueError(\"Invalid token passed!\")\n",
            "ValueError: Invalid token passed!\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers accelerate sentencepiece\n",
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZqC-zIarlxN",
        "outputId": "1feae306-bc49-4f69-a45d-83069dc3a2bf"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git@main accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWMPihNiG3iR",
        "outputId": "9a782a43-35ce-4747-f242-c0088d90b6dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[1mINFO    Running LLM\u001b[0m\n",
            "> \u001b[1mINFO    Params: Namespace(version=False, text_column='text', rejected_text_column='rejected', prompt_text_column='prompt', model_ref=None, warmup_ratio=0.1, optimizer='adamw_torch', scheduler='linear', weight_decay=0.0, max_grad_norm=1.0, add_eos_token=False, block_size=-1, peft=True, lora_r=16, lora_alpha=32, lora_dropout=0.05, logging_steps=-1, evaluation_strategy='epoch', save_total_limit=1, save_strategy='epoch', auto_find_batch_size=False, mixed_precision=None, quantization='int4', model_max_length=512, trainer='sft', target_modules=None, merge_adapter=True, use_flash_attention_2=False, dpo_beta=0.1, apply_chat_template=False, padding=None, train=True, deploy=False, inference=False, username=None, backend='local-cli', token=None, repo_id=None, push_to_hub=False, model='TinyPixel/CodeLlama-7B-Python-bf16-sharded', project_name='llama2-finetuning', seed=42, epochs=5, gradient_accumulation=1, disable_gradient_checkpointing=False, lr=0.0005, log='none', data_path='aaa', train_split='train', valid_split=None, batch_size=4, func=<function run_llm_command_factory at 0x7b83aea12320>)\u001b[0m\n",
            "> \u001b[1mINFO    Starting local training...\u001b[0m\n",
            "> \u001b[1mINFO    {\"model\":\"TinyPixel/CodeLlama-7B-Python-bf16-sharded\",\"project_name\":\"llama2-finetuning\",\"data_path\":\"aaa\",\"train_split\":\"train\",\"valid_split\":null,\"add_eos_token\":false,\"block_size\":-1,\"model_max_length\":512,\"padding\":null,\"trainer\":\"sft\",\"use_flash_attention_2\":false,\"log\":\"none\",\"disable_gradient_checkpointing\":false,\"logging_steps\":-1,\"evaluation_strategy\":\"epoch\",\"save_total_limit\":1,\"save_strategy\":\"epoch\",\"auto_find_batch_size\":false,\"mixed_precision\":null,\"lr\":0.0005,\"epochs\":5,\"batch_size\":4,\"warmup_ratio\":0.1,\"gradient_accumulation\":1,\"optimizer\":\"adamw_torch\",\"scheduler\":\"linear\",\"weight_decay\":0.0,\"max_grad_norm\":1.0,\"seed\":42,\"apply_chat_template\":false,\"quantization\":\"int4\",\"target_modules\":null,\"merge_adapter\":true,\"peft\":true,\"lora_r\":16,\"lora_alpha\":32,\"lora_dropout\":0.05,\"model_ref\":null,\"dpo_beta\":0.1,\"prompt_text_column\":\"prompt\",\"text_column\":\"text\",\"rejected_text_column\":\"rejected\",\"push_to_hub\":false,\"repo_id\":null,\"username\":null,\"token\":null}\u001b[0m\n",
            "> \u001b[1mINFO    ['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'llama2-finetuning/training_params.json']\u001b[0m\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
            "  warnings.warn(\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 7825.19it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 1265.63it/s]\n",
            "Generating train split: 961 examples [00:00, 35010.22 examples/s]\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-28 10:24:03\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1mTrain data: Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 961\n",
            "})\u001b[0m\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-28 10:24:03\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mValid data: None\u001b[0m\n",
            "tokenizer_config.json: 100% 773/773 [00:00<00:00, 3.73MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 10.5MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 8.16MB/s]\n",
            "special_tokens_map.json: 100% 411/411 [00:00<00:00, 2.05MB/s]\n",
            "config.json: 100% 1.05k/1.05k [00:00<00:00, 5.92MB/s]\n",
            "configuration_llama.py: 100% 8.56k/8.56k [00:00<00:00, 30.1MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/TheBloke/CodeLlama-7B-Python-fp16:\n",
            "- configuration_llama.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "modeling_llama.py: 100% 45.9k/45.9k [00:00<00:00, 846kB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/TheBloke/CodeLlama-7B-Python-fp16:\n",
            "- modeling_llama.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "pytorch_model.bin.index.json: 100% 23.9k/23.9k [00:00<00:00, 62.1MB/s]\n",
            "Downloading shards:   0% 0/7 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00007.bin:   0% 0.00/1.98G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:   1% 21.0M/1.98G [00:00<00:11, 173MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:   2% 41.9M/1.98G [00:00<00:10, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:   3% 62.9M/1.98G [00:00<00:10, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:   4% 83.9M/1.98G [00:00<00:09, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:   5% 105M/1.98G [00:00<00:11, 163MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00007.bin:   6% 126M/1.98G [00:00<00:11, 159MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:   7% 147M/1.98G [00:00<00:11, 155MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:   8% 168M/1.98G [00:01<00:11, 152MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  10% 189M/1.98G [00:01<00:11, 156MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  11% 210M/1.98G [00:01<00:10, 162MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  12% 231M/1.98G [00:01<00:10, 167MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  13% 252M/1.98G [00:01<00:10, 165MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  14% 273M/1.98G [00:01<00:10, 167MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  15% 294M/1.98G [00:01<00:10, 161MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  16% 315M/1.98G [00:01<00:10, 157MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  17% 336M/1.98G [00:02<00:10, 157MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  18% 357M/1.98G [00:02<00:10, 155MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  19% 377M/1.98G [00:02<00:10, 156MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  20% 398M/1.98G [00:02<00:10, 154MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  21% 419M/1.98G [00:02<00:15, 99.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  22% 440M/1.98G [00:03<00:17, 89.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  23% 461M/1.98G [00:03<00:14, 106MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  24% 482M/1.98G [00:03<00:12, 120MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  25% 503M/1.98G [00:03<00:11, 131MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  26% 524M/1.98G [00:03<00:10, 143MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  28% 545M/1.98G [00:03<00:09, 146MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  29% 566M/1.98G [00:03<00:09, 151MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  30% 587M/1.98G [00:04<00:09, 154MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  31% 608M/1.98G [00:04<00:09, 152MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  32% 629M/1.98G [00:04<00:09, 149MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  33% 650M/1.98G [00:04<00:08, 149MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  34% 671M/1.98G [00:04<00:08, 150MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  35% 692M/1.98G [00:04<00:08, 155MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  36% 713M/1.98G [00:04<00:07, 162MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  37% 734M/1.98G [00:04<00:07, 168MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  38% 755M/1.98G [00:05<00:07, 170MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  39% 776M/1.98G [00:05<00:07, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  40% 797M/1.98G [00:05<00:07, 164MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  41% 818M/1.98G [00:05<00:07, 159MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  42% 839M/1.98G [00:05<00:07, 160MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  43% 860M/1.98G [00:05<00:06, 167MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  44% 881M/1.98G [00:05<00:06, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  46% 912M/1.98G [00:05<00:05, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  48% 944M/1.98G [00:06<00:05, 201MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  49% 965M/1.98G [00:06<00:05, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  50% 986M/1.98G [00:06<00:05, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  51% 1.01G/1.98G [00:06<00:05, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  52% 1.03G/1.98G [00:06<00:05, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  53% 1.05G/1.98G [00:06<00:05, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  54% 1.07G/1.98G [00:08<00:22, 40.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  55% 1.09G/1.98G [00:08<00:17, 52.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  56% 1.11G/1.98G [00:08<00:12, 67.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  58% 1.14G/1.98G [00:08<00:09, 91.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  59% 1.16G/1.98G [00:08<00:07, 104MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  60% 1.18G/1.98G [00:08<00:07, 109MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  61% 1.21G/1.98G [00:08<00:06, 121MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  62% 1.24G/1.98G [00:09<00:05, 143MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  63% 1.26G/1.98G [00:09<00:04, 148MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  65% 1.28G/1.98G [00:09<00:04, 156MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  66% 1.30G/1.98G [00:09<00:04, 164MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  67% 1.33G/1.98G [00:09<00:03, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  68% 1.35G/1.98G [00:09<00:03, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  70% 1.38G/1.98G [00:09<00:03, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  71% 1.42G/1.98G [00:10<00:02, 204MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  73% 1.45G/1.98G [00:10<00:02, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  75% 1.48G/1.98G [00:10<00:02, 200MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  76% 1.50G/1.98G [00:10<00:02, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  77% 1.52G/1.98G [00:10<00:02, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  78% 1.54G/1.98G [00:10<00:02, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  79% 1.56G/1.98G [00:10<00:02, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  80% 1.59G/1.98G [00:10<00:01, 203MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  82% 1.63G/1.98G [00:11<00:01, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  83% 1.65G/1.98G [00:11<00:01, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  84% 1.67G/1.98G [00:11<00:01, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  85% 1.69G/1.98G [00:11<00:01, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  86% 1.71G/1.98G [00:11<00:01, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  87% 1.73G/1.98G [00:11<00:01, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  88% 1.75G/1.98G [00:11<00:01, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  89% 1.77G/1.98G [00:11<00:01, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  90% 1.79G/1.98G [00:11<00:01, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  92% 1.81G/1.98G [00:12<00:00, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  93% 1.84G/1.98G [00:12<00:00, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  94% 1.86G/1.98G [00:12<00:00, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  95% 1.88G/1.98G [00:12<00:00, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  96% 1.90G/1.98G [00:12<00:00, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  97% 1.92G/1.98G [00:12<00:00, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  98% 1.94G/1.98G [00:12<00:00, 191MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  99% 1.96G/1.98G [00:12<00:00, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin: 100% 1.98G/1.98G [00:12<00:00, 153MB/s]\n",
            "Downloading shards:  14% 1/7 [00:13<01:20, 13.40s/it]\n",
            "pytorch_model-00002-of-00007.bin:   0% 0.00/1.99G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   1% 10.5M/1.99G [00:00<00:30, 64.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   1% 21.0M/1.99G [00:00<00:28, 69.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   2% 31.5M/1.99G [00:00<00:24, 80.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   2% 41.9M/1.99G [00:00<00:22, 85.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   3% 62.9M/1.99G [00:00<00:19, 100MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   4% 83.9M/1.99G [00:00<00:16, 113MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   5% 105M/1.99G [00:01<00:15, 122MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   6% 126M/1.99G [00:01<00:14, 127MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   7% 147M/1.99G [00:01<00:14, 125MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   8% 168M/1.99G [00:01<00:14, 129MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   9% 189M/1.99G [00:01<00:13, 133MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  11% 210M/1.99G [00:01<00:13, 135MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  12% 231M/1.99G [00:01<00:13, 128MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  13% 252M/1.99G [00:02<00:13, 132MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  14% 273M/1.99G [00:02<00:12, 133MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  15% 294M/1.99G [00:02<00:12, 137MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  16% 315M/1.99G [00:02<00:12, 138MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  17% 336M/1.99G [00:02<00:11, 139MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  18% 357M/1.99G [00:02<00:11, 138MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  19% 377M/1.99G [00:03<00:11, 139MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  20% 398M/1.99G [00:03<00:11, 139MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  21% 419M/1.99G [00:03<00:11, 136MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  22% 440M/1.99G [00:03<00:11, 133MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  23% 461M/1.99G [00:03<00:10, 143MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  24% 482M/1.99G [00:03<00:10, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  25% 503M/1.99G [00:03<00:10, 141MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  26% 524M/1.99G [00:04<00:10, 134MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  27% 545M/1.99G [00:04<00:10, 133MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  28% 566M/1.99G [00:04<00:10, 132MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  30% 587M/1.99G [00:04<00:10, 136MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  31% 608M/1.99G [00:04<00:10, 137MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  32% 629M/1.99G [00:04<00:09, 139MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  33% 650M/1.99G [00:05<00:09, 137MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  34% 671M/1.99G [00:05<00:09, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  35% 692M/1.99G [00:05<00:09, 141MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  36% 713M/1.99G [00:05<00:09, 141MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  37% 734M/1.99G [00:05<00:08, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  38% 755M/1.99G [00:05<00:08, 139MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  39% 776M/1.99G [00:05<00:08, 139MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  40% 797M/1.99G [00:06<00:08, 138MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  41% 818M/1.99G [00:06<00:08, 141MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  42% 839M/1.99G [00:06<00:08, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  43% 860M/1.99G [00:06<00:08, 141MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  44% 881M/1.99G [00:06<00:07, 141MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  45% 902M/1.99G [00:06<00:07, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  46% 923M/1.99G [00:06<00:07, 141MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  47% 944M/1.99G [00:07<00:07, 141MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  48% 965M/1.99G [00:07<00:07, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  50% 986M/1.99G [00:07<00:07, 137MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  51% 1.01G/1.99G [00:07<00:07, 138MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  52% 1.03G/1.99G [00:07<00:06, 138MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  53% 1.05G/1.99G [00:07<00:06, 137MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  54% 1.07G/1.99G [00:10<00:36, 25.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  55% 1.09G/1.99G [00:10<00:26, 34.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  56% 1.11G/1.99G [00:10<00:23, 37.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  57% 1.13G/1.99G [00:10<00:17, 48.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  58% 1.15G/1.99G [00:11<00:15, 54.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  58% 1.16G/1.99G [00:11<00:14, 56.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  59% 1.17G/1.99G [00:11<00:13, 59.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  60% 1.18G/1.99G [00:11<00:12, 63.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  60% 1.20G/1.99G [00:11<00:11, 69.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  61% 1.21G/1.99G [00:11<00:10, 71.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  61% 1.22G/1.99G [00:12<00:11, 70.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  62% 1.23G/1.99G [00:12<00:10, 75.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  62% 1.24G/1.99G [00:12<00:09, 79.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  63% 1.25G/1.99G [00:12<00:09, 77.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  63% 1.26G/1.99G [00:12<00:10, 69.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  64% 1.28G/1.99G [00:12<00:08, 85.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  65% 1.29G/1.99G [00:12<00:08, 84.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  65% 1.30G/1.99G [00:13<00:09, 75.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  66% 1.32G/1.99G [00:13<00:07, 94.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  67% 1.34G/1.99G [00:13<00:06, 106MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  68% 1.36G/1.99G [00:13<00:05, 113MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  70% 1.38G/1.99G [00:13<00:05, 118MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  71% 1.41G/1.99G [00:13<00:04, 128MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  72% 1.43G/1.99G [00:13<00:04, 132MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  73% 1.45G/1.99G [00:14<00:04, 134MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  74% 1.47G/1.99G [00:14<00:03, 133MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  75% 1.49G/1.99G [00:15<00:09, 50.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  76% 1.51G/1.99G [00:15<00:07, 63.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  77% 1.53G/1.99G [00:15<00:05, 77.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  78% 1.55G/1.99G [00:15<00:04, 91.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  79% 1.57G/1.99G [00:15<00:04, 102MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  80% 1.59G/1.99G [00:16<00:03, 112MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  81% 1.61G/1.99G [00:16<00:03, 115MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  82% 1.64G/1.99G [00:16<00:03, 115MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  83% 1.66G/1.99G [00:16<00:02, 116MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  84% 1.68G/1.99G [00:16<00:02, 125MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  85% 1.70G/1.99G [00:16<00:02, 135MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  86% 1.72G/1.99G [00:16<00:01, 141MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  87% 1.74G/1.99G [00:17<00:01, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  89% 1.76G/1.99G [00:17<00:01, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  90% 1.78G/1.99G [00:17<00:01, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  91% 1.80G/1.99G [00:17<00:01, 137MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  92% 1.82G/1.99G [00:17<00:01, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  93% 1.85G/1.99G [00:17<00:01, 141MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  94% 1.87G/1.99G [00:17<00:00, 141MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  95% 1.89G/1.99G [00:19<00:02, 36.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  95% 1.90G/1.99G [00:19<00:02, 41.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  96% 1.91G/1.99G [00:19<00:01, 46.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  97% 1.93G/1.99G [00:19<00:00, 62.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  98% 1.95G/1.99G [00:20<00:00, 80.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  99% 1.97G/1.99G [00:20<00:00, 98.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin: 100% 1.99G/1.99G [00:20<00:00, 98.1MB/s]\n",
            "Downloading shards:  29% 2/7 [00:34<01:28, 17.70s/it]\n",
            "pytorch_model-00003-of-00007.bin:   0% 0.00/1.99G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:   2% 31.5M/1.99G [00:00<00:08, 219MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:   3% 62.9M/1.99G [00:00<00:08, 215MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:   5% 94.4M/1.99G [00:00<00:09, 206MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:   6% 115M/1.99G [00:00<00:09, 201MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00007.bin:   7% 136M/1.99G [00:00<00:09, 197MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:   8% 157M/1.99G [00:00<00:09, 192MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:   9% 178M/1.99G [00:00<00:09, 192MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  10% 199M/1.99G [00:01<00:09, 196MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  12% 231M/1.99G [00:01<00:08, 202MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  13% 262M/1.99G [00:01<00:08, 207MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  15% 294M/1.99G [00:01<00:08, 209MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  16% 315M/1.99G [00:01<00:08, 197MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  17% 336M/1.99G [00:01<00:08, 195MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  18% 367M/1.99G [00:01<00:07, 205MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  19% 388M/1.99G [00:01<00:07, 202MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  21% 409M/1.99G [00:02<00:07, 203MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  22% 440M/1.99G [00:02<00:07, 208MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  24% 472M/1.99G [00:02<00:07, 213MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  25% 503M/1.99G [00:02<00:06, 215MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  27% 535M/1.99G [00:02<00:07, 193MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  28% 556M/1.99G [00:02<00:07, 194MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  30% 587M/1.99G [00:02<00:06, 202MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  31% 619M/1.99G [00:03<00:06, 207MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  33% 650M/1.99G [00:03<00:06, 211MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  34% 682M/1.99G [00:03<00:06, 204MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  35% 703M/1.99G [00:03<00:06, 196MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  36% 724M/1.99G [00:03<00:06, 196MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  37% 744M/1.99G [00:03<00:06, 196MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  38% 765M/1.99G [00:03<00:06, 193MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  40% 786M/1.99G [00:04<00:16, 72.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  41% 807M/1.99G [00:04<00:13, 88.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  42% 839M/1.99G [00:04<00:10, 113MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  44% 870M/1.99G [00:04<00:08, 138MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  45% 891M/1.99G [00:05<00:10, 106MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  46% 923M/1.99G [00:05<00:08, 127MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  47% 944M/1.99G [00:05<00:07, 134MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  48% 965M/1.99G [00:05<00:07, 142MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  50% 986M/1.99G [00:05<00:06, 153MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  51% 1.01G/1.99G [00:05<00:05, 164MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  52% 1.03G/1.99G [00:06<00:05, 174MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  53% 1.06G/1.99G [00:06<00:04, 189MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  55% 1.09G/1.99G [00:06<00:04, 197MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  56% 1.12G/1.99G [00:06<00:04, 203MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  58% 1.15G/1.99G [00:06<00:04, 201MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  59% 1.17G/1.99G [00:06<00:04, 194MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  60% 1.20G/1.99G [00:06<00:04, 196MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  61% 1.22G/1.99G [00:06<00:03, 199MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  62% 1.24G/1.99G [00:07<00:03, 198MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  63% 1.26G/1.99G [00:07<00:03, 196MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  64% 1.28G/1.99G [00:09<00:26, 27.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  66% 1.31G/1.99G [00:09<00:16, 40.7MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  67% 1.33G/1.99G [00:09<00:12, 50.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  68% 1.35G/1.99G [00:10<00:10, 60.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  69% 1.37G/1.99G [00:10<00:08, 72.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  70% 1.39G/1.99G [00:10<00:06, 88.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  72% 1.43G/1.99G [00:10<00:05, 112MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  73% 1.45G/1.99G [00:10<00:04, 121MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  74% 1.47G/1.99G [00:10<00:03, 133MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  75% 1.49G/1.99G [00:10<00:03, 147MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  76% 1.52G/1.99G [00:10<00:02, 167MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  77% 1.54G/1.99G [00:11<00:02, 177MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  79% 1.57G/1.99G [00:11<00:02, 189MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  80% 1.59G/1.99G [00:11<00:02, 191MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  81% 1.61G/1.99G [00:11<00:02, 179MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  82% 1.64G/1.99G [00:11<00:02, 177MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  83% 1.66G/1.99G [00:11<00:01, 180MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  84% 1.68G/1.99G [00:11<00:01, 184MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  85% 1.70G/1.99G [00:11<00:01, 183MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  86% 1.72G/1.99G [00:14<00:11, 23.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  88% 1.75G/1.99G [00:14<00:06, 36.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  89% 1.77G/1.99G [00:14<00:04, 45.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  90% 1.79G/1.99G [00:15<00:03, 55.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  91% 1.81G/1.99G [00:15<00:02, 68.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  93% 1.85G/1.99G [00:15<00:01, 92.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  94% 1.87G/1.99G [00:15<00:01, 100MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  95% 1.89G/1.99G [00:15<00:00, 111MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  96% 1.92G/1.99G [00:15<00:00, 135MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  98% 1.95G/1.99G [00:15<00:00, 154MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin: 100% 1.99G/1.99G [00:16<00:00, 123MB/s]\n",
            "Downloading shards:  43% 3/7 [00:50<01:08, 17.20s/it]\n",
            "pytorch_model-00004-of-00007.bin:   0% 0.00/1.99G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:   2% 31.5M/1.99G [00:00<00:09, 215MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:   3% 62.9M/1.99G [00:00<00:09, 193MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:   4% 83.9M/1.99G [00:00<00:14, 131MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:   5% 105M/1.99G [00:00<00:14, 131MB/s] \u001b[A\n",
            "pytorch_model-00004-of-00007.bin:   6% 126M/1.99G [00:00<00:13, 142MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:   7% 147M/1.99G [00:03<01:09, 26.5MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:   8% 168M/1.99G [00:03<00:50, 36.1MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:   9% 189M/1.99G [00:03<00:37, 48.2MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  11% 210M/1.99G [00:03<00:28, 62.1MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  12% 231M/1.99G [00:03<00:22, 77.7MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  13% 252M/1.99G [00:03<00:18, 92.2MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  14% 273M/1.99G [00:03<00:16, 107MB/s] \u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  15% 294M/1.99G [00:04<00:18, 90.4MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  16% 315M/1.99G [00:04<00:16, 103MB/s] \u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  17% 336M/1.99G [00:04<00:14, 116MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  18% 357M/1.99G [00:04<00:12, 127MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  19% 377M/1.99G [00:04<00:11, 142MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  20% 398M/1.99G [00:04<00:10, 152MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  21% 419M/1.99G [00:04<00:09, 163MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  22% 440M/1.99G [00:04<00:09, 172MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  23% 461M/1.99G [00:05<00:09, 159MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  24% 482M/1.99G [00:05<00:09, 151MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  25% 503M/1.99G [00:05<00:09, 152MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  26% 524M/1.99G [00:05<00:09, 149MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  27% 545M/1.99G [00:05<00:09, 150MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  28% 566M/1.99G [00:08<00:55, 25.5MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  30% 587M/1.99G [00:08<00:41, 33.8MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  31% 608M/1.99G [00:08<00:31, 43.9MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  32% 629M/1.99G [00:08<00:24, 56.6MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  33% 650M/1.99G [00:08<00:18, 71.3MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  34% 671M/1.99G [00:08<00:15, 87.2MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  35% 692M/1.99G [00:08<00:12, 104MB/s] \u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  36% 713M/1.99G [00:08<00:10, 118MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  37% 734M/1.99G [00:09<00:09, 130MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  38% 755M/1.99G [00:09<00:09, 130MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  39% 776M/1.99G [00:09<00:08, 140MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  40% 797M/1.99G [00:09<00:08, 148MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  41% 818M/1.99G [00:09<00:07, 159MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  43% 849M/1.99G [00:09<00:06, 179MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  44% 870M/1.99G [00:09<00:06, 186MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  45% 891M/1.99G [00:09<00:06, 178MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  46% 912M/1.99G [00:10<00:06, 179MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  47% 933M/1.99G [00:10<00:05, 183MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  48% 954M/1.99G [00:10<00:05, 188MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  49% 975M/1.99G [00:12<00:30, 33.4MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  50% 996M/1.99G [00:12<00:22, 44.4MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  52% 1.03G/1.99G [00:12<00:14, 64.2MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  53% 1.05G/1.99G [00:12<00:12, 73.8MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  54% 1.07G/1.99G [00:12<00:10, 84.7MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  55% 1.10G/1.99G [00:12<00:08, 110MB/s] \u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  56% 1.12G/1.99G [00:12<00:07, 122MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  57% 1.14G/1.99G [00:13<00:06, 126MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  59% 1.17G/1.99G [00:13<00:05, 147MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  61% 1.21G/1.99G [00:13<00:04, 165MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  62% 1.24G/1.99G [00:13<00:04, 177MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  64% 1.27G/1.99G [00:13<00:03, 190MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  65% 1.29G/1.99G [00:13<00:03, 193MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  66% 1.31G/1.99G [00:13<00:03, 182MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  67% 1.34G/1.99G [00:14<00:03, 192MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  69% 1.37G/1.99G [00:14<00:03, 202MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  71% 1.41G/1.99G [00:14<00:02, 208MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  72% 1.44G/1.99G [00:14<00:02, 193MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  73% 1.46G/1.99G [00:14<00:02, 186MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  74% 1.48G/1.99G [00:14<00:02, 189MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  75% 1.50G/1.99G [00:14<00:02, 187MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  77% 1.53G/1.99G [00:15<00:02, 192MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  78% 1.55G/1.99G [00:15<00:02, 195MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  80% 1.58G/1.99G [00:15<00:02, 202MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  81% 1.61G/1.99G [00:15<00:01, 206MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  82% 1.64G/1.99G [00:15<00:01, 199MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  83% 1.66G/1.99G [00:15<00:01, 192MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  84% 1.68G/1.99G [00:15<00:01, 192MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  85% 1.70G/1.99G [00:15<00:01, 195MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  86% 1.72G/1.99G [00:15<00:01, 198MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  87% 1.74G/1.99G [00:16<00:01, 195MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  89% 1.76G/1.99G [00:16<00:02, 104MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  90% 1.78G/1.99G [00:16<00:01, 113MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  91% 1.80G/1.99G [00:16<00:01, 118MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  92% 1.82G/1.99G [00:16<00:01, 126MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  93% 1.85G/1.99G [00:17<00:01, 128MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  94% 1.87G/1.99G [00:17<00:00, 136MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  95% 1.89G/1.99G [00:17<00:00, 148MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  96% 1.91G/1.99G [00:17<00:00, 157MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  97% 1.93G/1.99G [00:17<00:00, 167MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  98% 1.95G/1.99G [00:17<00:00, 172MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  99% 1.97G/1.99G [00:17<00:00, 167MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin: 100% 1.99G/1.99G [00:18<00:00, 110MB/s]\n",
            "Downloading shards:  57% 4/7 [01:09<00:53, 17.70s/it]\n",
            "pytorch_model-00005-of-00007.bin:   0% 0.00/1.93G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:   2% 31.5M/1.93G [00:00<00:08, 229MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:   3% 62.9M/1.93G [00:00<00:09, 206MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:   4% 83.9M/1.93G [00:00<00:09, 204MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:   5% 105M/1.93G [00:00<00:08, 203MB/s] \u001b[A\n",
            "pytorch_model-00005-of-00007.bin:   7% 126M/1.93G [00:00<00:08, 203MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:   8% 147M/1.93G [00:00<00:09, 189MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:   9% 168M/1.93G [00:00<00:09, 190MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  10% 189M/1.93G [00:00<00:09, 188MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  11% 210M/1.93G [00:01<00:09, 187MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  12% 231M/1.93G [00:01<00:09, 189MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  13% 252M/1.93G [00:01<00:08, 189MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  14% 273M/1.93G [00:01<00:08, 194MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  15% 294M/1.93G [00:01<00:08, 193MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  17% 325M/1.93G [00:01<00:07, 202MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  18% 357M/1.93G [00:01<00:07, 208MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  20% 388M/1.93G [00:01<00:07, 212MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  22% 419M/1.93G [00:02<00:07, 198MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  23% 440M/1.93G [00:02<00:07, 191MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  24% 461M/1.93G [00:02<00:07, 187MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  25% 482M/1.93G [00:02<00:07, 191MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  26% 503M/1.93G [00:02<00:07, 190MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  27% 524M/1.93G [00:02<00:07, 193MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  29% 556M/1.93G [00:02<00:06, 201MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  30% 587M/1.93G [00:02<00:06, 206MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  32% 619M/1.93G [00:03<00:06, 212MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  34% 650M/1.93G [00:03<00:06, 194MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  35% 671M/1.93G [00:03<00:06, 191MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  36% 692M/1.93G [00:03<00:06, 190MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  37% 713M/1.93G [00:03<00:06, 190MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  38% 734M/1.93G [00:03<00:06, 190MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  39% 755M/1.93G [00:04<00:18, 63.2MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  40% 776M/1.93G [00:04<00:14, 79.0MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  42% 807M/1.93G [00:04<00:10, 104MB/s] \u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  43% 828M/1.93G [00:05<00:10, 105MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  44% 849M/1.93G [00:05<00:09, 116MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  46% 881M/1.93G [00:05<00:07, 140MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  47% 902M/1.93G [00:05<00:07, 146MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  48% 923M/1.93G [00:05<00:06, 150MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  49% 944M/1.93G [00:05<00:06, 159MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  50% 965M/1.93G [00:06<00:08, 115MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  52% 996M/1.93G [00:06<00:06, 141MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  53% 1.03G/1.93G [00:06<00:05, 161MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  55% 1.06G/1.93G [00:06<00:04, 177MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  56% 1.08G/1.93G [00:06<00:04, 178MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  57% 1.10G/1.93G [00:06<00:04, 177MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  58% 1.12G/1.93G [00:06<00:04, 180MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  59% 1.14G/1.93G [00:06<00:04, 182MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  60% 1.16G/1.93G [00:07<00:04, 183MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  61% 1.18G/1.93G [00:09<00:29, 25.1MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  62% 1.21G/1.93G [00:09<00:22, 32.4MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  63% 1.23G/1.93G [00:10<00:16, 41.8MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  65% 1.25G/1.93G [00:10<00:12, 54.2MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  66% 1.28G/1.93G [00:10<00:08, 76.6MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  67% 1.30G/1.93G [00:10<00:06, 91.3MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  68% 1.32G/1.93G [00:10<00:06, 99.3MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  69% 1.34G/1.93G [00:10<00:05, 107MB/s] \u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  70% 1.36G/1.93G [00:10<00:04, 121MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  72% 1.38G/1.93G [00:10<00:04, 136MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  73% 1.41G/1.93G [00:11<00:03, 147MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  74% 1.43G/1.93G [00:11<00:03, 160MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  75% 1.45G/1.93G [00:11<00:02, 168MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  76% 1.47G/1.93G [00:11<00:02, 163MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  77% 1.49G/1.93G [00:11<00:02, 155MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  78% 1.51G/1.93G [00:11<00:02, 151MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  79% 1.53G/1.93G [00:11<00:02, 156MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  80% 1.55G/1.93G [00:11<00:02, 157MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  81% 1.57G/1.93G [00:14<00:15, 23.3MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  82% 1.59G/1.93G [00:14<00:10, 31.2MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  84% 1.61G/1.93G [00:14<00:08, 39.4MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  85% 1.65G/1.93G [00:15<00:04, 58.1MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  87% 1.68G/1.93G [00:15<00:03, 78.8MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  88% 1.71G/1.93G [00:15<00:02, 99.8MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  89% 1.73G/1.93G [00:15<00:01, 106MB/s] \u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  91% 1.75G/1.93G [00:15<00:01, 120MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  92% 1.77G/1.93G [00:15<00:01, 135MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  93% 1.80G/1.93G [00:15<00:00, 156MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  95% 1.84G/1.93G [00:16<00:00, 173MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  96% 1.86G/1.93G [00:16<00:00, 173MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  97% 1.88G/1.93G [00:16<00:00, 175MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  98% 1.90G/1.93G [00:16<00:00, 182MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin: 100% 1.93G/1.93G [00:16<00:00, 117MB/s]\n",
            "Downloading shards:  71% 5/7 [01:26<00:34, 17.46s/it]\n",
            "pytorch_model-00006-of-00007.bin:   0% 0.00/1.93G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:   1% 21.0M/1.93G [00:00<00:17, 108MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:   2% 41.9M/1.93G [00:00<00:15, 124MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:   3% 62.9M/1.93G [00:00<00:15, 124MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:   4% 83.9M/1.93G [00:00<00:14, 124MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:   5% 105M/1.93G [00:00<00:13, 132MB/s] \u001b[A\n",
            "pytorch_model-00006-of-00007.bin:   7% 126M/1.93G [00:00<00:13, 136MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:   8% 147M/1.93G [00:01<00:13, 131MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:   9% 168M/1.93G [00:01<00:13, 134MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  10% 189M/1.93G [00:02<00:42, 41.1MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  11% 220M/1.93G [00:02<00:28, 59.1MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  12% 241M/1.93G [00:02<00:24, 68.5MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  14% 262M/1.93G [00:03<00:20, 83.2MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  15% 283M/1.93G [00:03<00:17, 97.1MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  16% 304M/1.93G [00:03<00:15, 106MB/s] \u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  17% 325M/1.93G [00:03<00:14, 114MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  18% 346M/1.93G [00:03<00:13, 117MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  19% 367M/1.93G [00:03<00:12, 124MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  20% 388M/1.93G [00:03<00:11, 129MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  21% 409M/1.93G [00:04<00:11, 133MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  22% 430M/1.93G [00:04<00:11, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  23% 451M/1.93G [00:04<00:10, 136MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  24% 472M/1.93G [00:04<00:10, 136MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  25% 493M/1.93G [00:04<00:10, 137MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  27% 514M/1.93G [00:04<00:10, 137MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  28% 535M/1.93G [00:04<00:10, 139MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  29% 556M/1.93G [00:05<00:09, 140MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  30% 577M/1.93G [00:05<00:09, 140MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  31% 598M/1.93G [00:06<00:32, 41.2MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  32% 619M/1.93G [00:06<00:24, 53.6MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  33% 640M/1.93G [00:06<00:20, 64.6MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  34% 661M/1.93G [00:07<00:16, 75.9MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  35% 682M/1.93G [00:07<00:13, 89.6MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  36% 703M/1.93G [00:07<00:12, 99.1MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  37% 724M/1.93G [00:07<00:11, 106MB/s] \u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  39% 744M/1.93G [00:07<00:10, 117MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  40% 765M/1.93G [00:07<00:09, 127MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  41% 786M/1.93G [00:07<00:08, 130MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  42% 807M/1.93G [00:08<00:08, 134MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  43% 828M/1.93G [00:08<00:08, 136MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  44% 849M/1.93G [00:08<00:08, 134MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  45% 870M/1.93G [00:08<00:07, 138MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  46% 891M/1.93G [00:08<00:07, 138MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  47% 912M/1.93G [00:08<00:07, 139MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  48% 933M/1.93G [00:09<00:07, 140MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  49% 954M/1.93G [00:09<00:07, 139MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  50% 975M/1.93G [00:09<00:06, 138MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  52% 996M/1.93G [00:09<00:06, 141MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  53% 1.02G/1.93G [00:09<00:06, 139MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  54% 1.04G/1.93G [00:09<00:06, 140MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  55% 1.06G/1.93G [00:09<00:06, 141MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  56% 1.08G/1.93G [00:10<00:06, 142MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  57% 1.10G/1.93G [00:10<00:07, 114MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  58% 1.12G/1.93G [00:12<00:31, 25.4MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  59% 1.14G/1.93G [00:12<00:23, 33.6MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  60% 1.16G/1.93G [00:12<00:17, 44.7MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  61% 1.18G/1.93G [00:13<00:13, 56.8MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  62% 1.21G/1.93G [00:13<00:10, 70.2MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  63% 1.23G/1.93G [00:13<00:08, 82.6MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  65% 1.25G/1.93G [00:13<00:07, 94.6MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  66% 1.27G/1.93G [00:13<00:06, 105MB/s] \u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  67% 1.29G/1.93G [00:13<00:05, 114MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  68% 1.31G/1.93G [00:13<00:05, 120MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  69% 1.33G/1.93G [00:14<00:04, 122MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  70% 1.35G/1.93G [00:14<00:04, 130MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  71% 1.37G/1.93G [00:14<00:04, 128MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  72% 1.39G/1.93G [00:14<00:04, 130MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  73% 1.42G/1.93G [00:14<00:03, 130MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  74% 1.44G/1.93G [00:14<00:03, 137MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  75% 1.46G/1.93G [00:15<00:03, 138MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  76% 1.48G/1.93G [00:15<00:03, 138MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  78% 1.50G/1.93G [00:15<00:03, 137MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  79% 1.52G/1.93G [00:17<00:15, 26.1MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  80% 1.54G/1.93G [00:17<00:11, 34.9MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  81% 1.56G/1.93G [00:17<00:08, 46.2MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  82% 1.58G/1.93G [00:18<00:06, 58.3MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  83% 1.60G/1.93G [00:18<00:04, 70.8MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  84% 1.63G/1.93G [00:18<00:03, 81.3MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  85% 1.65G/1.93G [00:18<00:03, 93.1MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  86% 1.67G/1.93G [00:18<00:02, 104MB/s] \u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  87% 1.69G/1.93G [00:18<00:02, 84.6MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  88% 1.71G/1.93G [00:19<00:02, 97.6MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  89% 1.73G/1.93G [00:19<00:01, 110MB/s] \u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  91% 1.75G/1.93G [00:19<00:01, 124MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  92% 1.77G/1.93G [00:19<00:01, 128MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  93% 1.79G/1.93G [00:19<00:01, 131MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  94% 1.81G/1.93G [00:19<00:00, 133MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  95% 1.84G/1.93G [00:19<00:00, 136MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  96% 1.86G/1.93G [00:20<00:00, 138MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  97% 1.88G/1.93G [00:20<00:00, 139MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  98% 1.90G/1.93G [00:20<00:00, 140MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  99% 1.92G/1.93G [00:20<00:00, 141MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin: 100% 1.93G/1.93G [00:22<00:00, 85.6MB/s]\n",
            "Downloading shards:  86% 6/7 [01:49<00:19, 19.35s/it]\n",
            "pytorch_model-00007-of-00007.bin:   0% 0.00/1.66G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:   2% 31.5M/1.66G [00:00<00:06, 235MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:   4% 62.9M/1.66G [00:00<00:07, 216MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:   6% 94.4M/1.66G [00:00<00:07, 213MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:   8% 126M/1.66G [00:00<00:07, 201MB/s] \u001b[A\n",
            "pytorch_model-00007-of-00007.bin:   9% 147M/1.66G [00:00<00:07, 199MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  10% 168M/1.66G [00:00<00:07, 196MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  11% 189M/1.66G [00:00<00:07, 189MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  13% 210M/1.66G [00:01<00:07, 188MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  14% 231M/1.66G [00:01<00:07, 191MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  15% 252M/1.66G [00:01<00:07, 192MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  16% 273M/1.66G [00:01<00:07, 194MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  18% 304M/1.66G [00:01<00:06, 204MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  20% 325M/1.66G [00:01<00:06, 200MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  22% 357M/1.66G [00:01<00:06, 196MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  23% 377M/1.66G [00:01<00:06, 192MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  24% 398M/1.66G [00:02<00:06, 190MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  25% 419M/1.66G [00:02<00:06, 189MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  27% 440M/1.66G [00:02<00:06, 190MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  28% 461M/1.66G [00:04<00:42, 27.9MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  29% 482M/1.66G [00:04<00:32, 36.5MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  30% 503M/1.66G [00:04<00:24, 47.8MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  32% 524M/1.66G [00:04<00:18, 61.2MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  33% 545M/1.66G [00:05<00:14, 74.7MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  34% 566M/1.66G [00:05<00:12, 90.6MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  35% 587M/1.66G [00:05<00:10, 106MB/s] \u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  37% 608M/1.66G [00:05<00:08, 119MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  38% 629M/1.66G [00:05<00:08, 118MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  39% 650M/1.66G [00:05<00:08, 119MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  41% 671M/1.66G [00:05<00:07, 130MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  42% 692M/1.66G [00:06<00:07, 136MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  43% 713M/1.66G [00:06<00:06, 144MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  44% 734M/1.66G [00:06<00:05, 154MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  46% 755M/1.66G [00:06<00:05, 164MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  47% 776M/1.66G [00:06<00:05, 169MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  48% 797M/1.66G [00:06<00:05, 147MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  49% 818M/1.66G [00:06<00:05, 151MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  51% 839M/1.66G [00:06<00:05, 149MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  52% 860M/1.66G [00:07<00:05, 152MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  53% 881M/1.66G [00:07<00:04, 155MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  54% 902M/1.66G [00:09<00:31, 23.8MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  56% 923M/1.66G [00:09<00:22, 32.3MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  57% 944M/1.66G [00:10<00:16, 43.0MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  58% 965M/1.66G [00:10<00:12, 55.4MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  59% 986M/1.66G [00:10<00:09, 70.2MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  61% 1.01G/1.66G [00:10<00:07, 84.7MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  62% 1.03G/1.66G [00:10<00:06, 99.6MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  63% 1.05G/1.66G [00:10<00:05, 114MB/s] \u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  65% 1.07G/1.66G [00:10<00:04, 129MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  66% 1.09G/1.66G [00:10<00:03, 143MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  67% 1.11G/1.66G [00:11<00:03, 148MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  69% 1.14G/1.66G [00:11<00:03, 169MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  71% 1.17G/1.66G [00:11<00:02, 185MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  72% 1.20G/1.66G [00:11<00:02, 185MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  73% 1.22G/1.66G [00:11<00:02, 179MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  75% 1.24G/1.66G [00:11<00:02, 173MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  76% 1.26G/1.66G [00:11<00:02, 176MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  77% 1.28G/1.66G [00:11<00:02, 180MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  78% 1.30G/1.66G [00:13<00:09, 37.0MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  80% 1.32G/1.66G [00:13<00:06, 48.7MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  81% 1.34G/1.66G [00:13<00:05, 59.6MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  82% 1.36G/1.66G [00:14<00:04, 71.5MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  84% 1.38G/1.66G [00:14<00:03, 88.4MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  85% 1.42G/1.66G [00:14<00:02, 115MB/s] \u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  87% 1.44G/1.66G [00:14<00:01, 130MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  88% 1.46G/1.66G [00:14<00:01, 131MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  89% 1.48G/1.66G [00:14<00:01, 145MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  91% 1.50G/1.66G [00:14<00:01, 153MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  92% 1.53G/1.66G [00:14<00:00, 172MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  94% 1.56G/1.66G [00:15<00:00, 187MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  96% 1.58G/1.66G [00:15<00:00, 184MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  97% 1.60G/1.66G [00:15<00:00, 189MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  98% 1.63G/1.66G [00:15<00:00, 188MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin: 100% 1.66G/1.66G [00:15<00:00, 106MB/s]\n",
            "Downloading shards: 100% 7/7 [02:05<00:00, 17.89s/it]\n",
            "Loading checkpoint shards:   0% 0/7 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Loading checkpoint shards: 100% 7/7 [01:01<00:00,  8.73s/it]\n",
            "generation_config.json: 100% 111/111 [00:00<00:00, 599kB/s]\n",
            "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-28 10:27:17\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mUsing block size 512\u001b[0m\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-28 10:27:17\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m339\u001b[0m - \u001b[1mcreating trainer\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:247: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n",
            "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
            "  0% 0/1205 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.6847, 'learning_rate': 0.00019834710743801655, 'epoch': 0.2}\n",
            "{'loss': 0.3734, 'learning_rate': 0.0003966942148760331, 'epoch': 0.4}\n",
            " 10% 126/1205 [50:19<6:42:47, 22.40s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.2784, 'learning_rate': 0.0004893911439114391, 'epoch': 1.07}\n",
            "{'loss': 0.232, 'learning_rate': 0.00046725092250922515, 'epoch': 1.27}\n",
            "{'loss': 0.1938, 'learning_rate': 0.00044511070110701107, 'epoch': 1.47}\n",
            " 21% 252/1205 [1:40:16<5:41:39, 21.51s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.1405, 'learning_rate': 0.0004229704797047971, 'epoch': 2.15}\n",
            "{'loss': 0.1174, 'learning_rate': 0.000400830258302583, 'epoch': 2.35}\n",
            " 31% 378/1205 [2:28:48<4:56:32, 21.51s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.1124, 'learning_rate': 0.00037869003690036904, 'epoch': 3.02}\n",
            "{'loss': 0.0801, 'learning_rate': 0.00035654981549815496, 'epoch': 3.22}\n",
            "{'loss': 0.0824, 'learning_rate': 0.000334409594095941, 'epoch': 3.42}\n",
            " 42% 504/1205 [3:17:19<4:11:27, 21.52s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.067, 'learning_rate': 0.00031226937269372696, 'epoch': 4.1}\n",
            " 46% 557/1205 [3:37:51<4:11:34, 23.29s/it]"
          ]
        }
      ],
      "source": [
        "!autotrain llm --train \\\n",
        "    --project-name \"llama2-finetuning\" \\\n",
        "    --model \"TinyPixel/CodeLlama-7B-Python-bf16-sharded\" \\\n",
        "    --data-path \"aaa\" \\\n",
        "    --text-column \"text\" \\\n",
        "    --peft \\\n",
        "    --quantization \"int4\" \\\n",
        "    --lr 5e-4 \\\n",
        "    --batch-size 4 \\\n",
        "    --epochs 5 \\\n",
        "    --trainer sft \\\n",
        "    --model_max_length 512 \\\n",
        "    --merge-adapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "UUMCVg0_jroN",
        "outputId": "8c7ca07d-88ad-4f17-ca49-5cb040166580"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_e0994683-fb39-4bad-84eb-3cd87744b275\", \"llama2-finetuning-da.zip\", 22)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import zipfile\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# 압축할 폴더 이름\n",
        "#folder_name = \"llama2-korquad-finetuning\"    # Data Augmentation 적용 x\n",
        "folder_name = \"llama2-finetuning-da\"  # Data Augmentation 적용 o\n",
        "\n",
        "# 생성될 ZIP 파일 이름\n",
        "#zip_file_name = \"llama2-korquad-finetuning.zip\"  # Data Augmentation 적용 x\n",
        "zip_file_name = \"llama2-finetuning-da.zip\" # Data Augmentation 적용 o\n",
        "\n",
        "# 폴더를 ZIP 파일로 압축\n",
        "shutil.make_archive(zip_file_name[:-4], 'zip', folder_name)\n",
        "\n",
        "# ZIP 파일을 로컬로 다운로드\n",
        "files.download(zip_file_name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
